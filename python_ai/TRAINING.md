# ğŸ§  Guia de Treinamento da IA (Reinforcement Learning)

Este documento explica como treinar o agente de Reinforcement Learning (RL) para jogar PokÃ©mon Red e os desafios conhecidos.

## ğŸš€ Como Treinar

O sistema usa **Proximal Policy Optimization (PPO)** atravÃ©s da biblioteca `stable-baselines3` em conjunto com o emulador `PyBoy`.

### Comando de Treinamento

Para iniciar o treinamento, certifique-se de que a configuraÃ§Ã£o `rl_enabled` estÃ¡ `true` em `config.json` e execute:

```bash
python main.py --train
```
*(Nota: O argumento `--train` precisa ser implementado se ainda nÃ£o existir, ou configure o script para modo de treinamento dedicadado)*

### ConfiguraÃ§Ã£o de HiperparÃ¢metros

Os hiperparÃ¢metros do modelo PPO podem ser ajustados em `python_ai/rl_layer/agent.py` (ou onde o modelo Ã© instanciado):

- **learning_rate**: Taxa de aprendizado (padrÃ£o: `0.0003`)
- **n_steps**: Passos por atualizaÃ§Ã£o (padrÃ£o: `2048`)
- **batch_size**: Tamanho do lote (padrÃ£o: `64`)
- **gamma**: Fator de desconto (padrÃ£o: `0.99`)

## âš ï¸ Problemas Conhecidos (Known Issues)

Durante o treinamento e inferÃªncia, o agente pode apresentar os seguintes comportamentos:

### 1. ğŸ”„ Ficar preso em cantos ou loops
**Sintoma:** O personagem anda em cÃ­rculos ou fica batendo na parede repetidamente.
**Causa:** O agente encontrou um mÃ¡ximo local de recompensa ou nÃ£o sabe como proceder para a prÃ³xima Ã¡rea.
**SoluÃ§Ã£o:**
- **IntervenÃ§Ã£o Manual:** Tome o controle do jogo temporariamente para mover o personagem para uma nova Ã¡rea.
- **Ajuste de Recompensa:** Incentive a exploraÃ§Ã£o (exploration bonus) no cÃ³digo de recompensa.

### 2. ğŸ›‘ Menus e DiÃ¡logos Infinitos
**Sintoma:** O agente fica preso em menus de batalha ou diÃ¡logos de texto.
**Causa:** O estado visual de menus Ã© complexo e o agente pode nÃ£o ter aprendido a sequÃªncia correta de botÃµes (A/B) para sair.
**SoluÃ§Ã£o:** Pressione 'A' ou 'B' manualmente para avanÃ§ar o texto.

### 3. ğŸ“‰ EstagnaÃ§Ã£o do Aprendizado
**Sintoma:** A recompensa mÃ©dia nÃ£o sobe apÃ³s milhÃµes de passos.
**Causa:** O ambiente de PokÃ©mon Ã© vasto e com recompensas esparsas (sparse rewards).
**SoluÃ§Ã£o:** Carregar `save states` de pontos mais avanÃ§ados do jogo para treinar o agente em cenÃ¡rios variados, em vez de sempre comeÃ§ar do inÃ­cio (Pallet Town).

## ğŸ® IntervenÃ§Ã£o Manual

A qualquer momento, vocÃª pode assumir o controle se o agente estiver travado.

1. Foque na janela do emulador/jogo.
2. Use as teclas configuradas (padrÃ£o: Setas + Z/X para A/B).
3. ApÃ³s desbloquear o personagem, solte os controles para a IA retomar.

## ğŸ“¦ DependÃªncias Externas ProprietÃ¡rias

Este projeto pode utilizar plugins Unity de terceiros, como **KlakNDI**, para captura de vÃ­deo e streaming.
- Se vocÃª nÃ£o tiver acesso a esse pacote, funcionalidades de vÃ­deo NDI nÃ£o funcionarÃ£o.
- Certifique-se de ter os direitos de uso de qualquer plugin proprietÃ¡rio adicionado ao projeto.
